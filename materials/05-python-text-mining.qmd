---
title: "\0"
format: 
  revealjs:
    css: ["theme/theme.css"]
    theme: simple
    preview-links: auto
    width: 1280
    height: 720
    filters: 
      - filter.lua
    footer: "[Introduction to Text Mining](https://mattfarrow1.github.io/apra-intro-to-text-mining/)"
    title-slide-attributes:
      data-background-image: "/materials/slide templates/Slide1.png"
      data-background-size: contain
      data-background-opacity: "1"
editor: visual
jupyter: python3
---

# Python

## Libraries

```{python}
#| echo: true

# General purpose
from collections import Counter
import numpy as np
import os
import warnings
warnings.filterwarnings(action = 'ignore')

# Data wrangling
import pandas as pd  # similar to tidyverse

# visualization
import matplotlib.pyplot as plt
import seaborn as sns
```

## Text Mining

```{python}
#| echo: true
#| warning: false
#| message: false

import nltk

nltk.download('stopwords')
nltk.download('wordnet')

from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from wordcloud import WordCloud
```

# Setup

## Load the data

```{python}
#| echo: true

# Import the data
df=pd.read_csv("workshop_data.csv", encoding='latin-1')
```

## Examine the data

```{python}
#| echo: true

df.head()
```

## Examine the data

```{python}
#| echo: true

df.info()
```

## Examine the data

```{python}
#| echo: true
df.shape
```

## Examine a Review

```{python}
#| echo: true

df.loc[:,'Review_Text'].values[10]
```

# Text Mining Prep

## Convert to lowercase

```{python}
#| echo: true

# Convert to lowercase
df['Review_Text'] = df['Review_Text'].apply(lambda x : ' '.join(x.lower() for x in x.split()))

df['Review_Text'].head()
```

## Remove Punctuation

```{python}
#| echo: true

# Remove punctuation
df['Review_Text'] = df['Review_Text'].str.replace('[^\w\s]', '')
```

## Remove Stop Words

```{python}
#| echo: true

stop = stopwords.words('english')
df['Review_Text'] = df['Review_Text'].apply(lambda x : " ".join(x for x in x.split() if x not in stop))
df['Review_Text'].head()
```

## Lemmatizing

```{python}
#| echo: true

lemmatizer = WordNetLemmatizer()
df['Review_Text'] = df['Review_Text'].apply(lambda x : " ".join(lemmatizer.lemmatize(word) for word in x.split()))
df['Review_Text'].head()
```

## Most Common Words

```{python}
#| echo: true
#| output-location: slide

most_common = Counter(' '.join(df['Review_Text']).split()).most_common(50)
most_common_df = pd.DataFrame(most_common, columns = ['Words', 'Freq'])
plt.figure(figsize = (18,6))
sns.barplot(data = most_common_df, x = 'Words', y = 'Freq')
plt.title('Most Common words')
plt.xticks(rotation = 60)
plt.show()
```

## Word Cloud

```{python}
#| echo: true
#| output-location: slide

word_index = Counter(" ".join(df['Review_Text']).split())
w_cloud = WordCloud(max_words = 1500, width = 800, height = 600).generate_from_frequencies(word_index, None)
plt.figure(figsize = (18, 6))
plt.imshow(w_cloud)
plt.axis('off')
plt.show()
```
