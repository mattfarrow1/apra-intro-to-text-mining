---
title: "\0"
format: 
  revealjs:
    width: 1920
    height: 1080
    css: ["theme/theme.css"]
    incremental: true 
    theme: simple
    preview-links: auto
    code-line-numbers: true
    echo: true
    filters: 
      - filter.lua
    footer: "[Introduction to Text Mining](https://mattfarrow1.github.io/apra-intro-to-text-mining/)"
    title-slide-attributes:
      data-background-image: "/materials/slide templates/Slide1.png"
      data-background-size: contain
      data-background-opacity: "1"
editor: source
---

# Visualize the Data

```{r echo=FALSE, message=FALSE}
library(tidyverse)
library(tidytext)
library(wordcloud)

df <- read_csv("DisneylandReviews.csv")

df <- df %>% 
  mutate(Branch = case_match(Branch, 
                             "Disneyland_California" ~ "California",
                             "Disneyland_HongKong" ~ "Hong Kong",
                             "Disneyland_Paris" ~ "Paris")) |> 
  rename("Park" = Branch)
```

## Distribution of ratings

```{r}
#| output-location: column-fragment
df |> 
  ggplot(aes(Rating)) +
  geom_bar(fill = "steelblue", color = "black") +
  labs(title = "Distribution of Ratings",
       x = "Rating",
       y = "Count") +
  scale_y_continuous(labels = scales::comma) +
  theme_minimal()
```

## By park (histogram)

```{r}
#| output-location: column-fragment
df |> 
  ggplot(aes(Rating, fill = Park)) +
  geom_bar(color = "black") +
  labs(title = "Distribution of Ratings by Park",
       x = "Rating",
       y = "Count",
       fill = "Park") +
  scale_y_continuous(labels = scales::comma) +
  scale_fill_discrete() +
  theme_minimal()
```

## By park (box plot)

```{r}
#| output-location: column-fragment

df |> 
  ggplot(aes(Park, Rating, color = Park)) +
  geom_boxplot(color = "black") +
  geom_jitter(alpha = 0.3) +
  labs(title = "Distribution of Ratings by Park",
       x = "Rating",
       y = "Count") +
  theme_minimal()
```

# Sample Data

## Sample Review

```{r}
#| output-location: fragment

df$Review_Text[15]
```

## Convert it to a tibble

```{r}
#| output-location: fragment

sample <- tibble(line = 1, text = df$Review_Text[15])
sample
```

## Unnest Tokens

```{r}
#| output-location: fragment

tidy_sample <- sample |> 
  unnest_tokens(word, text)
tidy_sample
```

## Word Count

```{r}
#| output-location: fragment

tidy_sample |> 
  count(word, sort = TRUE) |> 
  head()
```

## Word Count w/o Stop Words

```{r}
#| output-location: fragment

# Word count without stop words
tidy_sample |> 
  filter(!word %in% stop_words$word) |> 
  count(word, sort = TRUE) |> 
  head()
```

# Processing the Data

## Number Each Review

```{r}
#| output-location: fragment

# Number each review for each park
reviews <- df |>
  group_by(Park) |>
  mutate(linenumber = row_number()) |> 
  ungroup() |> 
  select(Park, linenumber, text = Review_Text) |> 
  arrange(Park, linenumber)

head(reviews)
```

## Unnest Tokens & Remove Stop Words

```{r}
#| output-location: fragment

# Unnest tokens and remove stop words
tidy_reviews <- reviews |> 
  unnest_tokens(word, text) |> 
  anti_join(stop_words)

head(tidy_reviews)
```

## Word Counts

```{r}
#| output-location: fragment

# Perform word count
tidy_reviews |> 
  count(word, sort = TRUE) |> 
  head()
```

## Word Clouds

```{r}
#| output-location: fragment
tidy_reviews |>
  anti_join(stop_words) |>
  count(word) |>
  with(wordcloud(word, n, max.words = 100))
```

## N-Grams

-   A continuous sequence of `n` words
-   Can be used 'as is', or run through a stemmer to get morphemes
-   Offers greater context than single words

## Bigrams (prep)

```{r}
#| output-location: fragment

# Unnest into bigrams
tidy_bigrams <- reviews |> 
  unnest_tokens(bigram, text, token = "ngrams", n = 2) |> 
  filter(!is.na(bigram))

# Separate words
tidy_bigrams <- tidy_bigrams |>
  separate(bigram, c("word1", "word2"), sep = " ")

# Remove stop words
tidy_bigrams <- tidy_bigrams |>
  filter(!word1 %in% stop_words$word) |>
  filter(!word2 %in% stop_words$word)

# Reunite terms
tidy_bigrams <- tidy_bigrams |>
  unite(bigram, word1, word2, sep = " ")
```

## Bigrams

```{r}
#| output-location: fragment

tidy_bigrams |> 
  group_by(Park) |> 
  count(bigram) |> 
  arrange(desc(n)) |> 
  head()
```

## Word & Document Frequencies

## Sentiment Analysis {.smaller}

An introduction using the 'joy' sentiment.

```{r}
#| output-location: fragment

# Get 'joy' sentiment
nrc_joy <- tidytext::get_sentiments("nrc")
nrc_joy <- nrc_joy |> 
  filter(sentiment == "joy")

head(nrc_joy)
```

## Sentiment Analysis {.smaller}

```{r}
#| output-location: fragment

# Most common 'joy' words in the reviews
tidy_reviews |>
  inner_join(nrc_joy) |>
  count(word, sort = TRUE) |> 
  head()
```

## Sentiment Analysis {.smaller}

```{r}
#| output-location: fragment

tidy_reviews_sentiment <- tidy_reviews |>
  inner_join(get_sentiments("bing")) |>
  count(Park, index = linenumber %/% 80, sentiment) |>
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) |>
  mutate(sentiment = positive - negative)

head(tidy_reviews_sentiment)
```

## Sentiment Analysis {.smaller}

```{r}
#| output-location: fragment

ggplot(tidy_reviews_sentiment, aes(index, sentiment, fill = Park)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ Park, ncol = 1, scales = "free_x") +
  labs(title = "Sentiment Analysis by Park") +
  theme_minimal()
```

## Topic Modeling
