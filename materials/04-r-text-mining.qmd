---
title: "\0"
format: 
  revealjs:
    css: ["theme/theme.css"]
    theme: simple
    preview-links: auto
    code-line-numbers: true
    filters: 
      - filter.lua
    footer: "[Introduction to Text Mining](https://mattfarrow1.github.io/apra-intro-to-text-mining/)"
    title-slide-attributes:
      data-background-image: "/materials/slide templates/Slide1.png"
      data-background-size: contain
      data-background-opacity: "1"
editor: visual
---

# Getting Started

## Setup

`r fontawesome::fa("laptop-code", "black")` Open `04-intro-to-r/01-ggplot2.R` in RStudio if you'd like to follow along.

::: {callout-tip}
Before we get started, it's a good idea to Restart R. That way nothing we did before carries through this section. (Session âž” Restart R)
:::

```{r}
#| echo: true
#| warning: false
#| message: false

# Install packages
# install.packages("tidyverse")
# install.packages("tidytext")
# install.packages("wordcloud")
# install.packages("here")

# Load libraries
library(tidyverse)
library(tidytext)
library(wordcloud)
library(here)
library(flipbookr)
```

## Load the data

```{r}
#| echo: true
#| output-location: column

# Load data
load(here::here("materials", "workshop_data.RData"))

df <- df |>
  mutate(Branch = case_match(Branch,
                             "Disneyland_California" ~ "California",
                             "Disneyland_HongKong" ~ "Hong Kong",
                             "Disneyland_Paris" ~ "Paris")) |>
  rename("Park" = Branch)
```

# Visualize the Data

## Why Visualize?

-   Gives us a sense of the data
-   See the distribution of the data
-   Raise questions to explore
-   Help shape your process

## Create a basic histogram

```{r}
#| label: basic-histogram
#| echo: true
#| output-location: column
#| code-line-numbers: true

df |> 
  ggplot(aes(x = Rating)) +
  geom_bar() +
  geom_bar(fill = "steelblue", color = "black") +
  geom_bar(fill = "steelblue", color = "black") +
  labs(title = "Distribution of Ratings",
       x = "Rating",
       y = "Count") +
  theme_minimal()
```

`r flipbookr:::chunq_reveal("basic-histogram", title = "Create a Basic Histogram", lcolw = "40", rcolw = "60", smallcode = TRUE)`

## Histogram by park

```{r}
#| label: park-histogram
#| echo: true
#| output-location: column
#| code-line-numbers: true

df |> 
  ggplot(aes(Rating, fill = Park)) +
  geom_bar() +
  geom_bar(color = "black") +
  labs(title = "Distribution of Ratings by Park",
       x = "Rating",
       y = "Count",
       fill = "Park") +
  scale_fill_brewer(palette = 3) + 
  theme_minimal() +
  theme(legend.position = "bottom")
```

`r flipbookr:::chunq_reveal("park-histogram", title = "Create a Histogram by Park", lcolw = "40", rcolw = "60", smallcode = TRUE)`

## Line plot

What if we wanted to look at the park ratings over time? What would we need to do?

-   Make sure `Year_Month` is a date
-   Group by `Park`
-   Count ratings per year

```{r}
#| echo: true
#| output-location: fragment

ratings_by_year <- df |> 
  mutate(Year = year(Year_Month),
         Month = month(Year_Month)) |> 
  group_by(Park) |> 
  count(Year) |> 
  rename(Ratings = n)

ratings_by_year
```

## Line plot

```{r}
#| label: reviews-by-year
#| echo: true
#| output-location: column
#| code-line-numbers: true

ratings_by_year |> 
  ggplot(aes(Year, Ratings, color = Park)) +
  geom_line() +
  labs(title = "Ratings by Park per Year",
       x = "Year",
       y = "Ratings") +
    scale_x_continuous(breaks = c(2010,
                                  2011,
                                  2012,
                                  2013,
                                  2014,
                                  2015,
                                  2016,
                                  2017,
                                  2018,
                                  2019,
                                  2020)) +
  ggthemes::theme_hc()
```

`r flipbookr:::chunq_reveal("reviews-by-year", title = "Park Reviews by Year", lcolw = "40", rcolw = "60", smallcode = TRUE)`

## Ridge plot

```{r}
#| echo: true
#| output-location: column

df |> 
  filter(Rating < 4) |> 
  mutate(Year_Month = ym(Year_Month),
         Year = year(Year_Month)) |> 
  group_by(Park, Year_Month) |> 
  # summarise(avg_rating = mean(Rating, na.rm = TRUE)) |> 
  ggplot(aes(x = Year_Month, y = Park)) +
  ggridges::geom_density_ridges(rel_min_height = 0.01,
                                scale = 1.5) +
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
  labs(title = "Distribution of Ratings by Park",
       x = "",
       y = "") +
  theme_minimal()
```

# Sample the data

## Look at one review

Brackets allow us to isolate a single cell.

```{r}
#| echo: true
#| output-location: column

df$Review_Text[11]
```

## Convert it to a `tibble`

```{r}
#| echo: true
#| output-location: column

sample <- tibble(line = 1, text = df$Review_Text[11])
sample
```

::: aside
[What is a tibble?](https://tibble.tidyverse.org/reference/tibble.html)
:::

## `unnest_tokens`

> "This place is HUGE! Definately need more than one day..."

<br>

```{r}
#| echo: true
#| output-location: column

sample |> 
  unnest_tokens(word, text)
```

## Advantages of `unnest_tokens`

-   splits text into one word/token per row along with the original line number
-   takes care of converting to lowercase
-   removes punctuation

# Process the data

## Number each review

```{r}
#| echo: true
#| output-location: fragment

# Number each review for each park
reviews <- df |>
  group_by(Park) |>
  mutate(linenumber = row_number()) |> 
  ungroup() |> 
  select(Park, linenumber, text = Review_Text) |> 
  arrange(Park, linenumber)

head(reviews)
```

## Unnest Tokens

```{r}
#| echo: true
#| output-location: fragment

# Unnest tokens
tidy_reviews <- reviews |> 
  unnest_tokens(word, text)

head(tidy_reviews)
```

## Stop Words

```{r}
#| echo: true
#| output-location: fragment

head(stop_words)
```

## `anti_join`

> An anti_join return all rows from the left table where there are not matching values in the right table, keeping just columns from the left table.

![](https://psyteachr.github.io/glossary/images/joins/anti_join.png){fig-align="center" height="500"}

::: aside
[Source](https://psyteachr.github.io/ads-v1/joins.html#anti_join)
:::

## Remove stop words

```{r}
#| echo: true
#| output-location: fragment

# Unnest tokens and remove stop words
tidy_reviews <- tidy_reviews |>
  anti_join(stop_words)

head(tidy_reviews)
```

## Create Word Counts

```{r}
#| echo: true
#| output-location: fragment

# Perform word count
tidy_reviews |> 
  count(word, sort = TRUE) |> 
  head()
```

# Word Clouds

## Create a word cloud

```{r}
#| echo: true
#| warning: false
#| message: false
#| output-location: fragment

tidy_reviews |> 
  count(word) |> 
  with(wordcloud(word, n, max.words = 40))
```

::: aside
What jumps out to you? How might we improve it?
:::

## Custom stop words

-   Stop word libraries are great starting points

-   Organization- or industry-specific terms may not be helpful

-   Custom stop word lists can filter these out

<br>

`wc_removals <- c("day", "disney", "disneyland", "rides")`

## Word Cloud without Custom Stop Words

```{r}
#| echo: true
#| warning: false
#| message: false
#| output-location: fragment

wc_removals <- c("day", "disney", "disneyland", "rides", "park")

tidy_reviews |>
  filter(!word %in% wc_removals) |> # note ! and %in%
  count(word) |>
  with(wordcloud(word, n, max.words = 50))
```

# N-Grams

-   A continuous sequence of `n` words
-   Can be used 'as is', or run through a stemmer to get morphemes
-   Offers more context than single words

## Set up bigrams

```{r}
#| echo: true
#| output-location: fragment

# Unnest into bigrams
tidy_bigrams <- reviews |> 
  unnest_tokens(bigram, text, token = "ngrams", n = 2) |> 
  filter(!is.na(bigram))

head(tidy_bigrams)
```

## Separate words

```{r}
#| echo: true
#| output-location: fragment

# Separate words
tidy_bigrams <- tidy_bigrams |>
  separate(bigram, c("word1", "word2"), sep = " ")

head(tidy_bigrams)
```

## Remove stop words

```{r}
#| echo: true
#| output-location: fragment

# Remove stop words
tidy_bigrams <- tidy_bigrams |>
  filter(!word1 %in% stop_words$word) |>
  filter(!word2 %in% stop_words$word)

head(tidy_bigrams)
```

## Reunite terms

```{r}
#| echo: true
#| output-location: fragment

# Reunite terms
tidy_bigrams <- tidy_bigrams |>
  unite(bigram, word1, word2, sep = " ")

head(tidy_bigrams)
```

## Look at top bigrams by park

```{r}
#| echo: true
#| output-location: fragment

tidy_bigrams |> 
  group_by(Park) |> 
  count(bigram) |> 
  arrange(desc(n)) |> 
  head()
```

# Word & Document Frequencies

## Total Words per Review

```{r}
#| echo: true
#| output-location: fragment

review_words <- tidy_reviews %>%
  count(Park, word, sort = TRUE)

total_words <- review_words %>% 
  group_by(Park) %>% 
  summarize(total = sum(n))

review_words <- left_join(review_words, total_words)

head(review_words)
```

## Review length by park

```{r}
#| echo: true
#| message: false
#| warning: false
#| output-location: fragment
ggplot(review_words, aes(n/total, fill = Park)) +
  geom_histogram(show.legend = FALSE) +
  xlim(NA, 0.001) +
  facet_wrap(~Park, ncol = 1, scales = "free_y") +
  theme_minimal()
```

## TF-IDF

```{r}
#| echo: true
#| output-location: fragment
freq_by_rank <- review_words %>% 
  group_by(Park) %>% 
  mutate(rank = row_number(), 
         `term frequency` = n/total) %>%
  ungroup()

head(freq_by_rank)
```

## Plot TF-IDF

```{r}
#| echo: true
#| output-location: slide
freq_by_rank %>% 
  ggplot(aes(rank, `term frequency`, color = Park)) + 
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10() +
  theme_minimal()
```

## Bigram TF-IDF

```{r}
#| echo: true
#| output-location: fragment

tidy_bigrams |> 
  count(Park, bigram) |> 
  bind_tf_idf(bigram, Park, n) |> 
  arrange(desc(tf_idf))
```

# Sentiment Analysis

An introduction using the 'joy' sentiment.

```{r}
#| output-location: fragment

# Get 'joy' sentiment
nrc_joy <- tidytext::get_sentiments("nrc")
nrc_joy <- nrc_joy |> 
  filter(sentiment == "joy")

head(nrc_joy)
```

## Sentiment Analysis {.smaller}

```{r}
#| output-location: fragment

# Most common 'joy' words in the reviews
tidy_reviews |>
  inner_join(nrc_joy) |>
  count(word, sort = TRUE) |> 
  head()
```

## Sentiment Analysis {.smaller}

```{r}
#| output-location: fragment

tidy_reviews_sentiment <- tidy_reviews |>
  inner_join(get_sentiments("bing")) |>
  count(Park, index = linenumber %/% 80, sentiment) |>
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) |>
  mutate(sentiment = positive - negative)

head(tidy_reviews_sentiment)
```

## Sentiment Analysis {.smaller}

```{r}
#| output-location: fragment

ggplot(tidy_reviews_sentiment, aes(index, sentiment, fill = Park)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ Park, ncol = 1, scales = "free_x") +
  labs(title = "Sentiment Analysis by Park") +
  theme_minimal()
```

## Topic Modeling
