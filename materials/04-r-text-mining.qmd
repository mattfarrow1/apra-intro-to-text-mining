---
title: "\0"
format: 
  revealjs:
    css: ["theme/theme.css"]
    theme: simple
    preview-links: auto
    code-line-numbers: true
    filters: 
      - filter.lua
    footer: "[Introduction to Text Mining](https://mattfarrow1.github.io/apra-intro-to-text-mining/)"
    title-slide-attributes:
      data-background-image: "/materials/slide templates/Slide1.png"
      data-background-size: contain
      data-background-opacity: "1"
editor: visual
---

# Visualize the Data

## Why Visualize?

-   Gives us a sense of the data
-   See the distribution of the data
-   Raise questions to explore
-   Help shape your process

## Basic histogram

```{r echo=FALSE, message=FALSE}
library(tidyverse)
library(tidytext)
library(wordcloud)

load("workshop_data.RData")
```

```{r}
#| echo: true
#| output-location: column

df |> 
  ggplot(aes(Rating)) +
  geom_bar()
```

## Add title and labels

```{r}
#| echo: true
#| output-location: column
#| code-line-numbers: "4-6"

df |> 
  ggplot(aes(Rating)) +
  geom_bar() +
  labs(title = "Distribution of Ratings",
       x = "Rating",
       y = "Count")
```

## Add color

```{r}
#| echo: true
#| output-location: column
#| code-line-numbers: "3"

df |> 
  ggplot(aes(Rating)) +
  geom_bar(fill = "steelblue", color = "black") +
  labs(title = "Distribution of Ratings",
       x = "Rating",
       y = "Count")
```

## Add a theme

```{r}
#| echo: true
#| output-location: column
#| code-line-numbers: "7"

df |> 
  ggplot(aes(Rating)) +
  geom_bar(fill = "steelblue", color = "black") +
  labs(title = "Distribution of Ratings",
       x = "Rating",
       y = "Count") +
  theme_minimal()
```

::: notes
Are there any thoughts or questions this raises?
:::

## Histogram by park

```{r}
#| echo: true
#| output-location: column
#| code-line-numbers: "2-3,5"

df |> 
  ggplot(aes(Rating, fill = Park)) +
  geom_bar(color = "black") +
  labs(title = "Distribution of Ratings by Park",
       x = "Rating",
       y = "Count",
       fill = "Park") +
  theme_minimal()
```

## Move legend

```{r}
#| echo: true
#| output-location: column
#| code-line-numbers: "10"

df |> 
  ggplot(aes(Rating, fill = Park)) +
  geom_bar(color = "black") +
  labs(title = "Distribution of Ratings by Park",
       x = "Rating",
       y = "Count",
       fill = "Park") +
  theme_minimal() +
  theme(legend.position = "bottom")
```

## Ratings over time

What if we wanted to look at the park ratings over time? What would we need to do?

-   Make sure `Year_Month` is a date
-   Group by `Park`
-   Count ratings per year

## Prepare the data

```{r}
#| echo: true
#| output-location: column

ratings_by_year <- df |> 
  filter(Year_Month != "missing") |> 
  mutate(Year_Month = ym(Year_Month),
         Year = year(Year_Month),
         Month = month(Year_Month)) |> 
  group_by(Park) |> 
  count(Year) |> 
  rename(Ratings = n)

ratings_by_year
```

## Line plot

```{r}
#| echo: true
#| output-location: column

ratings_by_year |> 
  ggplot(aes(Year, Ratings, color = Park)) +
  geom_line()
```

## Add title and labels

```{r}
#| echo: true
#| output-location: column

ratings_by_year |> 
  ggplot(aes(Year, Ratings, color = Park)) +
  geom_line() +
  labs(title = "Ratings by Park per Year",
       x = "Year",
       y = "Ratings")
```

## Custom x-axis

```{r}
#| echo: true
#| output-location: column
#| code-line-numbers: "14-24"

ratings_by_year |> 
  ggplot(aes(Year, Ratings, color = Park)) +
  geom_line() +
  labs(title = "Ratings by Park per Year",
       x = "Year",
       y = "Ratings") +
    scale_x_continuous(breaks = c(2010,
                                  2011,
                                  2012,
                                  2013,
                                  2014,
                                  2015,
                                  2016,
                                  2017,
                                  2018,
                                  2019,
                                  2020))
```

## Custom theme

```{r}
#| echo: true
#| output-location: column
#| code-line-numbers: "25"

df |> 
  filter(Year_Month != "missing") |> 
  mutate(Year_Month = ym(Year_Month),
         Year = year(Year_Month),
         Month = month(Year_Month)) |> 
  group_by(Park) |> 
  count(Year) |> 
  rename(Ratings = n) |> 
  ggplot(aes(Year, Ratings, color = Park)) +
  geom_line() +
  labs(title = "Ratings by Park per Year",
       x = "Year",
       y = "Ratings") +
    scale_x_continuous(breaks = c(2010,
                                  2011,
                                  2012,
                                  2013,
                                  2014,
                                  2015,
                                  2016,
                                  2017,
                                  2018,
                                  2019,
                                  2020)) +
  ggthemes::theme_hc()
```

## Ridge plot

```{r}
#| echo: true
#| output-location: column

df |> 
  filter(Year_Month != "missing",
         Rating < 4) |> 
  mutate(Year_Month = ym(Year_Month),
         Year = year(Year_Month)) |> 
  group_by(Park, Year_Month) |> 
  # summarise(avg_rating = mean(Rating, na.rm = TRUE)) |> 
  ggplot(aes(x = Year_Month, y = Park)) +
  ggridges::geom_density_ridges(rel_min_height = 0.01,
                                scale = 1.5) +
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
  labs(title = "Distribution of Ratings by Park",
       x = "",
       y = "") +
  theme_minimal()
```

# Sample the data

## Look at one review

```{r}
#| echo: true
#| output-location: column

df$Review_Text[15]
```

## Convert it to a `tibble`

```{r}
#| echo: true
#| output-location: column

sample <- tibble(line = 1, text = df$Review_Text[15])
sample
```

::: aside
[What is a tibble?](https://tibble.tidyverse.org/reference/tibble.html)
:::

## `unnest_tokens`

> "This place is HUGE! Definately need more than one day..."

<br>

```{r}
#| echo: true
#| output-location: column

tidy_sample <- sample |> 
  unnest_tokens(word, text)

head(tidy_sample)
```

## Advantages of `unnest_tokens`

-   splits text into one word/token per row along with the original line number
-   takes care of converting to lowercase
-   removes punctuation

# Process the data

## Number each review

```{r}
#| echo: true
#| output-location: fragment

# Number each review for each park
reviews <- df |>
  group_by(Park) |>
  mutate(linenumber = row_number()) |> 
  ungroup() |> 
  select(Park, linenumber, text = Review_Text) |> 
  arrange(Park, linenumber)

head(reviews)
```

## Unnest tokens & Remove Stop Words

```{r}
#| echo: true
#| output-location: fragment

# Unnest tokens and remove stop words
tidy_reviews <- reviews |> 
  unnest_tokens(word, text)

head(tidy_reviews)
```

## Stop Words

```{r}
#| echo: true
#| output-location: fragment

head(stop_words)
```

## `anti_join`

> An anti_join return all rows from the left table where there are not matching values in the right table, keeping just columns from the left table.

![](https://psyteachr.github.io/glossary/images/joins/anti_join.png){fig-align="center" height="500"}

::: aside
[Source](https://psyteachr.github.io/ads-v1/joins.html#anti_join)
:::

## Remove stop words

```{r}
#| echo: true
#| output-location: fragment

# Unnest tokens and remove stop words
tidy_reviews <- tidy_reviews |>
  anti_join(stop_words)

head(tidy_reviews)
```

## Word Counts

```{r}
#| echo: true
#| output-location: fragment

# Perform word count
tidy_reviews |> 
  count(word, sort = TRUE) |> 
  head()
```

## Set up word cloud

```{r}
#| echo: true
#| output-location: fragment
tidy_reviews |>
  anti_join(stop_words) |>
  count(word) |>
  with(wordcloud(word, n, max.words = 100))
```

::: aside
What jumps out to you? How might we improve it?
:::

## removing common words

```{r}
wc_removals <- c("disney", "park", "disneyland")

tidy_reviews |>
  anti_join(stop_words) |>
  filter(!word %in% wc_removals) |> 
  count(word) |>
  with(wordcloud(word, n, max.words = 100))
```


## N-Grams

-   A continuous sequence of `n` words
-   Can be used 'as is', or run through a stemmer to get morphemes
-   Offers greater context than single words

## Bigrams (prep)

```{r}
#| echo: true
#| output-location: fragment

# Unnest into bigrams
tidy_bigrams <- reviews |> 
  unnest_tokens(bigram, text, token = "ngrams", n = 2) |> 
  filter(!is.na(bigram))

# Separate words
tidy_bigrams <- tidy_bigrams |>
  separate(bigram, c("word1", "word2"), sep = " ")

# Remove stop words
tidy_bigrams <- tidy_bigrams |>
  filter(!word1 %in% stop_words$word) |>
  filter(!word2 %in% stop_words$word)

# Reunite terms
tidy_bigrams <- tidy_bigrams |>
  unite(bigram, word1, word2, sep = " ")
```

## Bigrams

```{r}
#| output-location: fragment

tidy_bigrams |> 
  group_by(Park) |> 
  count(bigram) |> 
  arrange(desc(n)) |> 
  head()
```

## Word & Document Frequencies

## Sentiment Analysis {.smaller}

An introduction using the 'joy' sentiment.

```{r}
#| output-location: fragment

# Get 'joy' sentiment
nrc_joy <- tidytext::get_sentiments("nrc")
nrc_joy <- nrc_joy |> 
  filter(sentiment == "joy")

head(nrc_joy)
```

## Sentiment Analysis {.smaller}

```{r}
#| output-location: fragment

# Most common 'joy' words in the reviews
tidy_reviews |>
  inner_join(nrc_joy) |>
  count(word, sort = TRUE) |> 
  head()
```

## Sentiment Analysis {.smaller}

```{r}
#| output-location: fragment

tidy_reviews_sentiment <- tidy_reviews |>
  inner_join(get_sentiments("bing")) |>
  count(Park, index = linenumber %/% 80, sentiment) |>
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) |>
  mutate(sentiment = positive - negative)

head(tidy_reviews_sentiment)
```

## Sentiment Analysis {.smaller}

```{r}
#| output-location: fragment

ggplot(tidy_reviews_sentiment, aes(index, sentiment, fill = Park)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ Park, ncol = 1, scales = "free_x") +
  labs(title = "Sentiment Analysis by Park") +
  theme_minimal()
```

## Topic Modeling
