---
title: "\0"
format: 
  revealjs:
    css: ["theme/theme.css"]
    scss: ["theme/custom.scss"]
    theme: simple
    preview-links: auto
    code-line-numbers: true
    code-annotations: hover
    width: 1280
    height: 720
    filters: 
      - filter.lua
    footer: "[Introduction to Text Mining](https://mattfarrow1.github.io/apra-intro-to-text-mining/)"
    title-slide-attributes:
      data-background-image: "/materials/slide templates/Slide1.png"
      data-background-size: contain
      data-background-opacity: "1"
      smaller: true
editor: visual
---

# Getting Started {background-image="/materials/slide templates/Slide3.png" background-size="contain"}

## Setup

`r fontawesome::fa("laptop-code", "black")` Open `04-intro-to-r/01-ggplot2.R` in RStudio if you'd like to follow along.

::: {.callout-tip}
Before we get started, it's a good idea to Restart R. That way nothing we did before carries through this section. (Session âž” Restart R)
:::

## Setup

```{r}
#| echo: true
#| eval: false
#| warning: false
#| message: false

# Install packages
# install.packages("tidyverse")
# install.packages("tidytext")
# install.packages("wordcloud")
# install.packages("here")

# Load libraries
library(tidyverse)
library(tidytext)
library(wordcloud)
library(here)
```

```{r}
#| echo: false
library(tidyverse)
library(tidytext)
library(wordcloud)
library(here)
library(flipbookr)
```

## Load the data

```{r}
#| echo: true

# Load data
load(here::here("materials", "workshop_data.RData"))

df <- df |>
  mutate(Branch = case_match(Branch,
                             "Disneyland_California" ~ "California",
                             "Disneyland_HongKong" ~ "Hong Kong",
                             "Disneyland_Paris" ~ "Paris")) |>
  rename("Park" = Branch)
```

# Visualize the Data {background-image="/materials/slide templates/Slide3.png" background-size="contain"}

## Why Visualize?

-   Gives us a sense of the data
-   See the distribution of the data
-   Raise questions to explore
-   Help shape your process

## Create a basic histogram

```{r}
#| label: basic-histogram
#| echo: false
#| eval: false
#| output-location: column
#| code-line-numbers: true

ggplot(df, aes(x = Rating)) +
  geom_bar() +
  geom_bar(
    fill = "steelblue",
    color = "black"
  ) +
  labs(
    title = "Distribution of Ratings",
    x = "Rating",
    y = "Count"
  ) +
  theme_minimal()
```

`r flipbookr:::chunq_reveal("basic-histogram", title = "Create a basic histogram", lcolw = "40", rcolw = "60", smallcode = TRUE)`

## Histogram by park

```{r}
#| label: park-histogram
#| echo: false
#| eval: false
#| output-location: column
#| code-line-numbers: true

ggplot(df, aes(Rating,
  fill = Park
)) +
  geom_bar() +
  geom_bar(color = "black") +
  labs(
    title = "Distribution of Ratings by Park",
    x = "Rating",
    y = "Count",
    fill = "Park"
  ) +
  scale_fill_brewer(palette = 3) +
  theme_gray() +
  theme(legend.position = "bottom")
```

`r flipbookr:::chunq_reveal("park-histogram", title = "Histogram by park", lcolw = "40", rcolw = "60", smallcode = TRUE)`

## Reviews by year

What if we wanted to look at the park ratings over time? What would we need to do?

-   Make sure `Year_Month` is a date
-   Group by `Park`
-   Count ratings per year

## Reviews by year

```{r}
#| echo: true
#| output-location: column-fragment

ratings_by_year <- df |> 
  mutate(Year = year(Year_Month),
         Month = month(Year_Month)) |> 
  group_by(Park) |> 
  count(Year) |> 
  rename(Ratings = n)

ratings_by_year
```

## Reviews by year

```{r}
#| label: reviews-by-year
#| echo: false
#| eval: false
#| output-location: column-fragment
#| code-line-numbers: true

ggplot(
  ratings_by_year,
  aes(Year,
    Ratings,
    color = Park
  )
) +
  geom_line() +
  labs(
    title = "Ratings by Park per Year",
    x = "Year",
    y = "Ratings"
  ) +
  scale_x_continuous(
    breaks = c(
      2010,
      2011,
      2012,
      2013,
      2014,
      2015,
      2016,
      2017,
      2018,
      2019,
      2020
    )
  ) +
  ggthemes::theme_economist()
```

`r flipbookr:::chunq_reveal("reviews-by-year", title = "Reviews by year", lcolw = "40", rcolw = "60", smallcode = TRUE)`

# Sample the data {background-image="/materials/slide templates/Slide3.png" background-size="contain"}

## Look at one review

Brackets allow us to isolate a single cell.

```{r}
#| echo: true
#| output-location: column

df$Review_Text[11]
```

## Convert it to a `tibble`

```{r}
#| echo: true
#| output-location: column

sample <- tibble(
  line = 1,
  text = df$Review_Text[11]
)
sample
```

::: aside
[What is a tibble?](https://tibble.tidyverse.org/reference/tibble.html)
:::

## `unnest_tokens`

> "I went there with 2 daughters 1 y.o and 4..."

<br>

```{r}
#| echo: true
#| output-location: column

sample |>
  unnest_tokens(word, text)
```

## Advantages of `unnest_tokens`

-   splits text into one word/token per row along with the original line number
-   takes care of converting to lowercase
-   removes punctuation

# Process the data {background-image="/materials/slide templates/Slide3.png" background-size="contain"}

## Number each review

```{r}
#| echo: true
#| output-location: column-fragment

reviews <- df |>
  group_by(Park) |>
  mutate(linenumber = row_number()) |>
  ungroup() |>
  select(Park,
    linenumber,
    text = Review_Text
  ) |>
  arrange(
    Park,
    linenumber
  )

head(reviews)
```

## Unnest Tokens

```{r}
#| echo: true
#| output-location: fragment

# Unnest tokens
tidy_reviews <- reviews |> 
  unnest_tokens(word, text)

head(tidy_reviews)
```

## Stop Words

```{r}
#| echo: true
#| output-location: fragment

head(stop_words)
```

## `anti_join`

> An anti_join return all rows from the left table where there are not matching values in the right table, keeping just columns from the left table.

![](https://psyteachr.github.io/glossary/images/joins/anti_join.png){fig-align="center" height="500"}

::: aside
[Source](https://psyteachr.github.io/ads-v1/joins.html#anti_join)
:::

## Remove stop words

```{r}
#| echo: true
#| output-location: fragment

# Unnest tokens and remove stop words
tidy_reviews <- tidy_reviews |>
  anti_join(stop_words)

head(tidy_reviews)
```

## Create Word Counts

```{r}
#| echo: true
#| output-location: column-fragment

# Perform word count
tidy_reviews |> 
  count(word, sort = TRUE) |> 
  head()
```

# Word Clouds {background-image="/materials/slide templates/Slide3.png" background-size="contain"}

## Create a word cloud

```{r}
#| echo: true
#| warning: false
#| message: false
#| output-location: slide

set.seed(1234)

tidy_reviews |>
  count(word) |>
  with(wordcloud(word, 
                 n, 
                 max.words = 40,
                 colors=brewer.pal(8, "Dark2")))
```

::: aside
What jumps out to you? How might we improve it?
:::

## Custom stop words

-   Stop word libraries are great starting points

-   Organization- or industry-specific terms may not be helpful

-   Custom stop word lists can filter these out

<br>

`wc_removals <- c("day", "disney", "disneyland", "rides")`

## Word Cloud without Custom Stop Words

```{r}
#| echo: true
#| warning: false
#| message: false
#| output-location: slide

wc_removals <- c("day", "disney", "disneyland", "rides", "park")

tidy_reviews |>
  filter(!word %in% wc_removals) |>        # <1>
  count(word) |>
  with(wordcloud(word, 
                 n, 
                 max.words = 50,
                 colors=brewer.pal(8, "Dark2")))
```

1. The `%in%` syntax allows you to look for a match inside a vector or column.

# N-Grams {background-image="/materials/slide templates/Slide3.png" background-size="contain"}

-   A continuous sequence of `n` words
-   Can be used 'as is', or run through a stemmer to get morphemes
-   Offers more context than single words

## Set up bigrams

```{r}
#| echo: true
#| output-location: column-fragment

# Unnest into bigrams
tidy_bigrams <- reviews |> 
  unnest_tokens(bigram, 
                text, 
                token = "ngrams", 
                n = 2) |> 
  filter(!is.na(bigram))

head(tidy_bigrams)
```

## Separate words

```{r}
#| echo: true
#| output-location: fragment

# Separate words
tidy_bigrams <- tidy_bigrams |>
  separate(bigram, 
           c("word1", 
             "word2"), 
           sep = " ")

head(tidy_bigrams)
```

## Remove stop words

```{r}
#| echo: true
#| output-location: fragment

# Remove stop words
tidy_bigrams <- tidy_bigrams |>
  filter(!word1 %in% stop_words$word) |>
  filter(!word2 %in% stop_words$word)

head(tidy_bigrams)
```

## Reunite terms

```{r}
#| echo: true
#| output-location: fragment

# Reunite terms
tidy_bigrams <- tidy_bigrams |>
  unite(bigram, word1, word2, sep = " ")

head(tidy_bigrams)
```

## Look at top bigrams by park

```{r}
#| echo: true
#| output-location: fragment

tidy_bigrams |> 
  group_by(Park) |> 
  count(bigram) |> 
  arrange(desc(n)) |> 
  head()
```

# Word Frequencies {background-image="/materials/slide templates/Slide3.png" background-size="contain"}

## Total Words per Review

```{r}
#| echo: true
#| output-location: fragment

review_words <- tidy_reviews %>%
  count(Park, word, sort = TRUE)

total_words <- review_words %>% 
  group_by(Park) %>% 
  summarize(total = sum(n))

review_words <- left_join(review_words, total_words)

head(review_words)
```

## Review length by park

```{r}
#| echo: true
#| message: false
#| warning: false
#| output-location: slide
ggplot(review_words, 
       aes(n/total, 
           fill = Park)) +
  geom_histogram(show.legend = FALSE) +
  xlim(NA, 0.001) +
  facet_wrap(~ Park, 
             ncol = 1, 
             scales = "free_y") +
  theme_minimal()
```

## TF-IDF

```{r}
#| echo: true
#| output-location: fragment
freq_by_rank <- review_words %>% 
  group_by(Park) %>% 
  mutate(rank = row_number(), 
         `term frequency` = n/total) %>%
  ungroup()

head(freq_by_rank)
```

## Plot TF-IDF

```{r}
#| echo: true
#| output-location: slide
freq_by_rank %>% 
  ggplot(aes(rank, `term frequency`, color = Park)) + 
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10() +
  theme_minimal()
```

## Bigram TF-IDF

```{r}
#| echo: true
#| output-location: fragment

tidy_bigrams |> 
  count(Park, bigram) |> 
  bind_tf_idf(bigram, Park, n) |> 
  arrange(desc(tf_idf))
```

# Sentiment analysis {background-image="/materials/slide templates/Slide3.png" background-size="contain"}

## Sentiment analysis

An introduction using the 'joy' sentiment.

```{r}
#| echo: true
#| output-location: fragment

# Get 'joy' sentiment
nrc_joy <- tidytext::get_sentiments("nrc")
nrc_joy <- nrc_joy |> 
  filter(sentiment == "joy")

head(nrc_joy)
```

## Sentiment Analysis

```{r}
#| echo: true
#| output-location: fragment

# Most common 'joy' words in the reviews
tidy_reviews |>
  inner_join(nrc_joy) |>
  count(word, sort = TRUE) |> 
  head()
```

## Sentiment Analysis

```{r}
#| echo: true
#| output-location: fragment

tidy_reviews_sentiment <- tidy_reviews |>
  inner_join(get_sentiments("bing")) |>
  count(Park, index = linenumber %/% 80, sentiment) |>
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) |>
  mutate(sentiment = positive - negative)

head(tidy_reviews_sentiment)
```

## Sentiment Analysis

```{r}
#| echo: true
#| output-location: fragment

ggplot(tidy_reviews_sentiment, aes(index, sentiment, fill = Park)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ Park, ncol = 1, scales = "free_x") +
  labs(title = "Sentiment Analysis by Park") +
  theme_minimal()
```