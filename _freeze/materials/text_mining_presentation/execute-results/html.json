{
  "hash": "22a4ac49b3b8323281a35ac8c78d1045",
  "result": {
    "markdown": "---\ntitle: \"\\0\"\nformat: \n  revealjs:\n    css: style.css\n    preview-links: auto\n    filters: \n      - filter.lua\neditor: visual\ntitle-slide-attributes:\n    data-background-image: \"/materials/slide templates/Slide1.png\"\n    data-background-size: contain\n    data-background-opacity: \"1\"\nexecute:\n  freeze: auto\n---\n\n\n\n# Overall Goals\n\n-   Into to Text Mining\n-   Keyword searches in Excel\n-   Getting started with R\n-   Text mining in R\n-   Text mining in Python\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(tidytext)\nlibrary(wordcloud)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: RColorBrewer\n```\n:::\n:::\n\n\n\n## Poll\n\n1.  What do you think of when I say text mining?\n2.  How much experience do you have with coding languages like R or Python?\n3.  What types of things are you most interested in? (keywords, sentiment, ngrams, word clouds...)\n\n# Intro to Text Mining {background-image=\"/materials/slide templates/Slide3.png\" background-size=\"contain\"}\n\n## What is text mining?\n\nText mining is the process of extracting information and insights from unstructured text.\n\n## Terms to Know\n\n-   **Natural Language**: A natural language, as opposed to an artificially created language such as R or Python, develops gradually and often without thought, over time. (*Examples include English or Italian.*)\n-   **Natural Language Processing (NLP)**: refers to the creation and use of computational power in order to process content in natural language.\n\n## Terms to Know\n\n-   **Segmentation/Tokenization**: the process of splitting apart pieces of language. *Sentence segmentation* is the process of breaking sentences apart using tokenizers to examine punctuation, abbreviations, and capitalization. *Word tokenization* involves breaking out the individual words of a sentence.\n\n## Terms to Know\n\n-   **Text Normalization**: involves standardizing text prior to analysis. Examples include the expansion of contractions (don't -\\> do not), removal of stop words (of, and, it), correcting misspellings, and stemming (if required)\n\n## Terms to Know\n\n-   **Term Frequency**: measures how often a term appears in a document.\n-   **Document Frequency**: measures how often a term appears in a corpus of documents.\n\n## Terms to Know\n\n-   **Inverse Document Frequency**: a number computed by dividing the total number of documents in the corpus by the number of documents containing the target term and applying a log scale.\n-   **TF-IDF**: \"Term Frequency-Inverse Document Frequency\". Higher term frequency and a lower document frequency leads to a higher TF-IDF.\n\n## Levels of Analysis\n\n-   **Lexical Analysis**: The most basic form of NLP, lexical analysis is focused on analyzing individual words.\n-   **Syntactic Analysis**: concerned with processing the grammar of written words.\n-   **Semantic Analysis**: builds on lexical and syntactic analyses in order to understand the meanings of words.\n-   **Discourse Analysis**: Understanding inferences in language is the domain of discourse analysis.\n\n## Choosing a Tool\n\n-   **Experience**: what do you know best?\n-   **Availability**: what do you have access to?\n-   **Support**: where can you turn when you have problems?\n-   **Longevity**: if you win the lottery tomorrow can someone take over?\n\n# Excel {background-image=\"/materials/slide templates/Slide3.png\" background-size=\"contain\"}\n\n## Excel Agenda\n\n-   Pros and Cons\n-   Formulas\n-   Using ChatGPT to help with formulas\n-   Keyword Search\n-   Word Count\n\n## Pros and Cons\n\n::: columns\n:::\n\n**Pros** - Universally available - Not going anywhere - Low barrier to entry - Scales in complexity\n\n:::\n\n:::\n\n**Cons** - Can be difficult to reproduce - Potentially destructive - Doesn't scale well - Limited options for text mining\n\n:::\n\n::::\n\n## Formula: vlookup\n\n=**VLOOKUP**(<font color=\"red\">Value to look up</font>, <font color=\"blue\">Range to look for value</font>, <font color=\"orange\">Column for the return value</font>, <font color=\"green\">Type of match</font>)\\\n=VLOOKUP(<font color=\"red\">A1</font>, <font color=\"blue\">Lookup!A1:B7</font>, <font color=\"orange\">2</font>, <font color=\"green\">TRUE</font>)\n\n## Formula: absolute/relative references\n\nRelative references **can** move.\n\nA1\n\nAbsolute references **can't** move.\n\n\\$A\\$1\n\n## Formula: absolute/relative references\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl <- tibble::tribble(\n~`$A$2`, ~`The column and the row do not change when copied.`,\n\"A$2\",\"The row does not change when copied.\",\n\"$A2\",\"The column does not change when copied.\"\n)\n\nkableExtra::kable_styling(knitr::kable(tbl), font_size = 24)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"font-size: 24px; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> $A$2 </th>\n   <th style=\"text-align:left;\"> The column and the row do not change when copied. </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> A$2 </td>\n   <td style=\"text-align:left;\"> The row does not change when copied. </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> $A2 </td>\n   <td style=\"text-align:left;\"> The column does not change when copied. </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n## Formula: countif\n\n=**COUNTIF**(<font color=\"red\">Where are we looking?</font>, <font color=\"blue\">What are we looking for?</font>)\n\n=COUNTIF(<font color=\"red\">A:A</font>, <font color=\"blue\">\"Washington\"</font>)\n\n## ChatGPT for Formula Help\n\n::: callout-warning\nAssume that everything you put into ChatGPT (or other LLMs) is public. Do not enter confidential or proprietary information into it.\n:::\n\nTell ChatGPT what is is you need assistance with:\n\n![](images/chatgpt-excel-1.png){fig-align=\"center\"}\n\n## ChatGPT for Formula Help\n\n![](images/chatgpt-excel-2.png){fig-align=\"center\"}\n\n## Formula: keyword search\n\nSource: ChatGPT\n\n=IF(SUMPRODUCT(--ISNUMBER(SEARCH(Keywords_Range, Cell)))\\>0, \"Found\", \"Not Found\")\n\n## Formula: keyword search\n\n=IF(SUMPRODUCT(--ISNUMBER(SEARCH(<font color=\"red\">Keywords_Range</font>, Cell)))\\>0, \"Found\", \"Not Found\")\n\n1.  Replace `Keywords_Range` with the actual range of keywords you want to search for. For example, if your keywords are in cells A1 to A10, the range would be `A1:A10`.\n\n## Formula: keyword search\n\n=IF(SUMPRODUCT(--ISNUMBER(SEARCH(Keywords_Range, <font color=\"red\">Cell</font>)))\\>0, \"Found\", \"Not Found\")\n\n2.  Replace `Cell` with the cell reference of the cell in the column you want to search. This is the cell where you want to check if any of the keywords are present. For example, if you want to search in column B, and the first cell is B2, you would use `B2` as the cell reference.\n\n## Formula: keyword search\n\nSource: ChatGPT\n\n=IF(SUMPRODUCT(--ISNUMBER(SEARCH(Keywords_Range, Cell)))\\>0, \"Found\", \"Not Found\")\n\n3.  Enter the formula in the cell where you want the search result to appear.\n\nThe formula will return \"Found\" if any of the keywords in the range are found in the specified cell, and \"Not Found\" if none of the keywords are found.\n\nNote: This formula is case-insensitive, so it will match keywords regardless of their case. If you want case-sensitive matching, you can use the `FIND` function instead of `SEARCH` in the formula.\n\n# R {background-image=\"/materials/slide templates/Slide3.png\" background-size=\"contain\"}\n\n## Getting Started\n\n1.  What is R?\n2.  R vs. Python?\n\n::: notes\nR is a programming language started by professors Ross Ihaka and Robert Gentleman as a programming language to teach introductory statistics at the University of Auckland. It was developed in the early 1990's and open sourced in 1995.\n\nFor the purposes of this workshop, there are no significant differences in R vs. Python other than the language and packages/libraries used. I chose to start with R because that's where I'm most comfortable, it's the language that I see Apra promoting, and the community is incredibly welcoming and diverse.\n:::\n\n## Getting Started\n\n::: callout-tip\nEverything in this workshop can be done through the virtual project. Scan the QR code to get started.\n:::\n\n![](images/qr_code.png){height=\"250\" fig-align=\"center\"}\n\n::: notes\nDiscuss the layout of RStudio and what people are looking at.\n:::\n\n## RStudio IDE/Posit Cloud\n\n![](images/rstudio-1.png){fig-align=\"center\" height=\"500\"}\n\n## RStudio IDE/Posit Cloud\n\n![](images/rstudio-2.png){fig-align=\"center\" height=\"500\"}\n\n## Packages\n\n-   Libraries of code\n-   Expand the \"base R\" code\n\n## The `tidyverse`\n\n![](images/tidyverse-logo.png){fig-align=\"center\" height=\"200\"}\n\n-   [What is it?](https://www.tidyverse.org)\n-   How does it work?\n\n## The `tidyverse` vs 'Base R'\n\n![](images/dplyr-vs-base-r.png){fig-align=\"center\" height=\"350\"}\n\nSource: [dplyr base R](https://dplyr.tidyverse.org/articles/base.html)\n\n## `tidytext`\n\n![](images/tidytext-logo.png){fig-align=\"center\" height=\"200\"}\n\n-   What is it?\n-   How does it work?\n\n# The Data\n\n42,656 reviews from Disney California, Hong Kong, and Paris\n\n![](images/disney-logo.png){fig-align=\"center\" height=\"200\"}\n\nSource: [Kaggle](https://www.kaggle.com/datasets/arushchillar/disneyland-reviews)\n\n## Getting Started\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Install libraries\n# install.packages(\"tidyverse\")\n# install.packages(\"tidytext\")\n\n# Load libraries\nlibrary(tidyverse)\nlibrary(tidytext)\n\n# Read in the data\ndf <- read_csv(\"DisneylandReviews.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 42656 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): Year_Month, Reviewer_Location, Review_Text, Branch\ndbl (2): Review_ID, Rating\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n:::\n\n\n\n## Examine the Data {.smaller}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# head(df)\n# str(df)\nglimpse(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 42,656\nColumns: 6\n$ Review_ID         <dbl> 670772142, 670682799, 670623270, 670607911, 67060729…\n$ Rating            <dbl> 4, 4, 4, 4, 4, 3, 5, 3, 2, 5, 5, 5, 4, 5, 5, 3, 4, 3…\n$ Year_Month        <chr> \"2019-4\", \"2019-5\", \"2019-4\", \"2019-4\", \"2019-4\", \"2…\n$ Reviewer_Location <chr> \"Australia\", \"Philippines\", \"United Arab Emirates\", …\n$ Review_Text       <chr> \"If you've ever been to Disneyland anywhere you'll f…\n$ Branch            <chr> \"Disneyland_HongKong\", \"Disneyland_HongKong\", \"Disne…\n```\n:::\n:::\n\n\n\n## Look at the Parks\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(df$Branch)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Disneyland_HongKong\"   \"Disneyland_California\" \"Disneyland_Paris\"     \n```\n:::\n:::\n\n\n\n## Clean up Park Names\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- df %>% \n  rename(Park = Branch) %>% \n  mutate(Park = recode(Park,\n                       \"Disneyland_California\" = \"California\",\n                       \"Disneyland_HongKong\" = \"Hong Kong\",\n                       \"Disneyland_Paris\" = \"Paris\"\n  ))\n\nunique(df$Park)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Hong Kong\"  \"California\" \"Paris\"     \n```\n:::\n:::\n\n\n\n## Examine the Data {.smaller}\n\n\n\n::: {.cell output-location='column-fragment'}\n\n```{.r .cell-code}\ndf %>% \n  ggplot(aes(Rating)) +\n  geom_bar(fill = \"steelblue\", color = \"black\") +\n  labs(title = \"Distribution of Ratings\",\n       x = \"Rating\",\n       y = \"Count\") +\n  scale_y_continuous(labels = scales::comma) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](text_mining_presentation_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n## Examine the Data {.smaller}\n\n\n\n::: {.cell output-location='column-fragment'}\n\n```{.r .cell-code}\ndf %>% \n  ggplot(aes(Rating, fill = Park)) +\n  geom_bar(color = \"black\") +\n  labs(title = \"Distribution of Ratings by Park\",\n       x = \"Rating\",\n       y = \"Count\",\n       fill = \"Park\") +\n  scale_y_continuous(labels = scales::comma) +\n  scale_fill_discrete() +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](text_mining_presentation_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n## Examine the Data {.smaller}\n\n\n\n::: {.cell output-location='column-fragment'}\n\n```{.r .cell-code}\ndf %>% \n  ggplot(aes(Park, Rating, color = Park)) +\n  geom_boxplot(color = \"black\") +\n  geom_jitter(alpha = 0.3) +\n  labs(title = \"Distribution of Ratings by Park\",\n       x = \"Rating\",\n       y = \"Count\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](text_mining_presentation_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n# Sample Data\n\n## Sample Review {.smaller}\n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\ndf$Review_Text[15]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"This place is HUGE! Definately need more than one day. We had 3 children aged 11, 9 & 6 and they loved it. A great variety of rides and attractions for all ages. Food options were fantastic with 3D models of what you were ordering. Staff were fantastic, very helpful. An awesome family experience.\"\n```\n:::\n:::\n\n\n\n## Sample Review {.smaller}\n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\n# Convert it to a tibble\nsample <- tibble(line = 1, text = df$Review_Text[15])\nsample\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 2\n   line text                                                                    \n  <dbl> <chr>                                                                   \n1     1 This place is HUGE! Definately need more than one day. We had 3 childre…\n```\n:::\n:::\n\n\n\n## Sample Review: Unnest Tokens {.smaller}\n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\n# Unnest tokens\ntidy_sample <- sample %>% \n  unnest_tokens(word, text)\ntidy_sample\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 53 × 2\n    line word      \n   <dbl> <chr>     \n 1     1 this      \n 2     1 place     \n 3     1 is        \n 4     1 huge      \n 5     1 definately\n 6     1 need      \n 7     1 more      \n 8     1 than      \n 9     1 one       \n10     1 day       \n# ℹ 43 more rows\n```\n:::\n:::\n\n\n\n## Sample Review: Word Count {.smaller}\n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\n# Word count\ntidy_sample %>% \n  count(word, sort = TRUE) %>% \n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 2\n  word          n\n  <chr>     <int>\n1 were          3\n2 and           2\n3 fantastic     2\n4 of            2\n5 11            1\n6 3             1\n```\n:::\n:::\n\n\n\n## Sample Review: Word Count w/o Stop Words {.smaller}\n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\n# Word count without stop words\ntidy_sample %>% \n  filter(!word %in% stop_words$word) %>% \n  count(word, sort = TRUE) %>% \n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 2\n  word          n\n  <chr>     <int>\n1 fantastic     2\n2 11            1\n3 3             1\n4 3d            1\n5 6             1\n6 9             1\n```\n:::\n:::\n\n\n\n# Processing the Data\n\n## Number Each Review {.smaller}\n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\n# Number each review for each park\nreviews <- df %>%\n  group_by(Park) %>%\n  mutate(linenumber = row_number()) %>% \n  ungroup() %>% \n  select(Park, linenumber, text = Review_Text) %>% \n  arrange(Park, linenumber)\n\nhead(reviews)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 3\n  Park       linenumber text                                                    \n  <chr>           <int> <chr>                                                   \n1 California          1 This place has always been and forever will be special.…\n2 California          2 A great day of simple fun and thrills. Bring cash, noth…\n3 California          3 All and all a great day was had. The crowds are huge an…\n4 California          4 Having been to the Florida location numerous times over…\n5 California          5 Had the 4 day pass, spent 3 at DL and one at CA. Great …\n6 California          6 Oh my god you can really forget your self and enjoy eve…\n```\n:::\n:::\n\n\n\n## Unnest Tokens & Remove Stop Words {.smaller}\n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\n# Unnest tokens and remove stop words\ntidy_reviews <- reviews %>% \n  unnest_tokens(word, text) %>% \n  anti_join(stop_words)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(word)`\n```\n:::\n\n```{.r .cell-code}\nhead(tidy_reviews)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 3\n  Park       linenumber word      \n  <chr>           <int> <chr>     \n1 California          1 forever   \n2 California          1 special   \n3 California          1 feeling   \n4 California          1 entering  \n5 California          1 park      \n6 California          1 characters\n```\n:::\n:::\n\n\n\n## Word Counts {.smaller}\n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\n# Perform word count\ntidy_reviews %>% \n  count(word, sort = TRUE) %>% \n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 2\n  word           n\n  <chr>      <int>\n1 park       44557\n2 disney     36187\n3 rides      34508\n4 disneyland 32935\n5 time       29432\n6 day        28332\n```\n:::\n:::\n\n\n\n## Word Clouds\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_reviews %>%\n  anti_join(stop_words) %>%\n  count(word) %>%\n  with(wordcloud(word, n, max.words = 100))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(word)`\n```\n:::\n\n::: {.cell-output-display}\n![](text_mining_presentation_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\n## N-Grams\n\n-   A continuous sequence of `n` words\n-   Can be used 'as is', or run through a stemmer to get morphemes\n-   Offers greater context than single words\n\n## Bigrams (prep)\n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\n# Unnest into bigrams\ntidy_bigrams <- reviews %>% \n  unnest_tokens(bigram, text, token = \"ngrams\", n = 2) %>% \n  filter(!is.na(bigram))\n\n# Separate words\ntidy_bigrams <- tidy_bigrams %>%\n  separate(bigram, c(\"word1\", \"word2\"), sep = \" \")\n\n# Remove stop words\ntidy_bigrams <- tidy_bigrams %>%\n  filter(!word1 %in% stop_words$word) %>%\n  filter(!word2 %in% stop_words$word)\n\n# Reunite terms\ntidy_bigrams <- tidy_bigrams %>%\n  unite(bigram, word1, word2, sep = \" \")\n```\n:::\n\n\n\n## Bigrams\n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\ntidy_bigrams %>% \n  group_by(Park) %>% \n  count(bigram) %>% \n  arrange(desc(n)) %>% \n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 3\n# Groups:   Park [3]\n  Park       bigram                   n\n  <chr>      <chr>                <int>\n1 California fast pass             3123\n2 Hong Kong  hong kong             3025\n3 Paris      disneyland paris      2932\n4 California california adventure  2293\n5 Paris      fast pass             1940\n6 California disney world          1926\n```\n:::\n:::\n\n\n\n## Word & Document Frequencies\n\n## Sentiment Analysis {.smaller}\n\nAn introduction using the 'joy' sentiment.\n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\n# Get 'joy' sentiment\nnrc_joy <- tidytext::get_sentiments(\"nrc\")\nnrc_joy <- nrc_joy %>% \n  filter(sentiment == \"joy\")\n\nhead(nrc_joy)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 2\n  word          sentiment\n  <chr>         <chr>    \n1 absolution    joy      \n2 abundance     joy      \n3 abundant      joy      \n4 accolade      joy      \n5 accompaniment joy      \n6 accomplish    joy      \n```\n:::\n:::\n\n\n\n## Sentiment Analysis {.smaller}\n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\n# Most common 'joy' words in the reviews\ntidy_reviews %>%\n  inner_join(nrc_joy) %>%\n  count(word, sort = TRUE) %>% \n  head()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(word)`\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 2\n  word        n\n  <chr>   <int>\n1 food    14322\n2 fun      9952\n3 parade   8468\n4 love     5967\n5 magical  5190\n6 enjoy    4807\n```\n:::\n:::\n\n\n\n## Sentiment Analysis {.smaller}\n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\ntidy_reviews_sentiment <- tidy_reviews %>%\n  inner_join(get_sentiments(\"bing\")) %>%\n  count(Park, index = linenumber %/% 80, sentiment) %>%\n  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%\n  mutate(sentiment = positive - negative)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(word)`\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in inner_join(., get_sentiments(\"bing\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 846927 of `x` matches multiple rows in `y`.\nℹ Row 2579 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n```\n:::\n\n```{.r .cell-code}\nhead(tidy_reviews_sentiment)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 5\n  Park       index negative positive sentiment\n  <chr>      <dbl>    <int>    <int>     <int>\n1 California     0      144      313       169\n2 California     1      174      310       136\n3 California     2      149      340       191\n4 California     3      143      283       140\n5 California     4      170      399       229\n6 California     5      123      266       143\n```\n:::\n:::\n\n\n\n## Sentiment Analysis {.smaller}\n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\nggplot(tidy_reviews_sentiment, aes(index, sentiment, fill = Park)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ Park, ncol = 1, scales = \"free_x\") +\n  labs(title = \"Sentiment Analysis by Park\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](text_mining_presentation_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n\n## Topic Modeling\n\n# Python\n\n## Python Libraries\n\n## Recreating R Work\n\n# Learning More\n\nRelated to this Workshop\n\n-   [R for Data Science](https://r4ds.had.co.nz)\n-   [Text Mining with R](https://www.tidytextmining.com/index.html)\n\nOther R Links\n\n-   [Big Book of R](https://www.bigbookofr.com)\n\n# Get in Touch\n\nmatt.farrow\\@childrens.com\n\n#  {background-image=\"/materials/slide templates/Slide8.png\" background-size=\"contain\"}\n",
    "supporting": [
      "text_mining_presentation_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}